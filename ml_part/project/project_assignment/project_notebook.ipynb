{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product recommendation engine\n",
    "---\n",
    "![](resources/groceries.jpg)\n",
    "\n",
    "## Main objective:\n",
    "---\n",
    "Imagine we are a grocery store owner, and we are trying to maximize the purchases of our customers per visit. \n",
    "\n",
    "A first strategy that comes to our mind is placing products next to each other that are usually bought together.\n",
    "\n",
    "Since we have succesfully completed a Data Science task in the past we immediately realize that this problem can be formulated as a recommendation task.\n",
    "\n",
    "\n",
    "The machine learning part has the following goal:\n",
    "\n",
    "\n",
    "Essentially we will try to predict the last item of a customers purchase list, given all the other items that he has already in his shopping basket. Those predictions are a helpful first heuristic for the placement of certain products in our grocery store. \n",
    "\n",
    "Thus we start collecting the purchase histories of past customers and start writing down the following steps needed, to build our recommendation pipeline:\n",
    "\n",
    "\n",
    "### Plan of attack:\n",
    "1. Load the customer purchase data, located in 'data/training_data.csv', 'data/training_labels.csv'\n",
    "    - Note on the dataset: Each row in each of the data files refers to one 'incomplete' item-list of a customers purchase.\n",
    "    - The labels represent the item that was purchased by the customer in addition to the items in the dataset\n",
    "    \n",
    "    \n",
    "2. Plot the following statistics on the joined datasets(train_x + train_y):\n",
    "\n",
    "    - histogram of 10 most purchased products\n",
    "    - pie chart of all product purchase frequencies(use top ten frequencies)\n",
    "    - which other interesting plots can you think of ? -> extra points\n",
    "    \n",
    "\n",
    "3. Compute and present the following results on joined data sets, train_x + train_y(you are free to choose any method to present your results):\n",
    "\n",
    "    - Find the pair of products, that are bought together the most\n",
    "    - Which product was the least purchased ?\n",
    "\n",
    "\n",
    "4. Transform it into a Machine learning-classifier digestable format:\n",
    "    - Machine learning algorithms consume data, that has a unified format!\n",
    "    - For example it should look like that:\n",
    "    \n",
    "    \n",
    "    | feature 1(e.g. product/grocery): | feature 2: | ... | feature N: |\n",
    "    | \"apple\"                          | \"banana\"   | ... | mango      |\n",
    "    --------------------------------------------------------------------\n",
    "    | no                               | yes        | ... | no         | <- customer 1: purchased only banana \n",
    "    --------------------------------------------------------------------\n",
    "    | yes                              | yes        | ... | yes        | <- customer 2: purchased all 3 shown\n",
    "    -------------------------------------------------------------------- \n",
    "                                .\n",
    "                                .\n",
    "                                .\n",
    "    --------------------------------------------------------------------\n",
    "    | no                              | no         | ... | no          | <- customer N: purchased nothing\n",
    "    --------------------------------------------------------------------\n",
    "    \n",
    "\n",
    "\n",
    "5. Train your model on the training set(=train_x, train_y), and predict an item for the each row in the test set(=test_x).DON'T change the order of the test set:\n",
    "\n",
    "    - Item-predictions should be in the original string format(=item name)\n",
    "    - You can predict numerical values and then convert them back into strings\n",
    "\n",
    "6. Save the predictions(=string representations) for the test set in a csv-file\n",
    "\n",
    "\n",
    "### Note on implementation:\n",
    "- You are free to use any classification algorithm that you want. If you find better recommendation approaches on the web(there certainly are better, but also more involved ones), you are free to use those.\n",
    "- Some proven algorithms, other than the ones learned in the lectures are: \n",
    "    - https://towardsdatascience.com/intro-to-recommender-system-collaborative-filtering-64a238194a26\n",
    "    - https://towardsdatascience.com/prototyping-a-recommender-system-step-by-step-part-1-knn-item-based-collaborative-filtering-637969614ea\n",
    "\n",
    "### Note on grading:\n",
    "- End result on the classification task = 25%\n",
    "- Clean code(e.g. classes instead of script like functions etc.) = 25 %\n",
    "- Documentation = 25%\n",
    "- Usage of numpy, pandas, pyplot etc. functions for faster computation = 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pd.read_csv('data/training_data.csv', header=None)\n",
    "test_x = pd.read_csv('data/test_data.csv', header=None)\n",
    "train_y = pd.read_csv('data/training_labels.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
