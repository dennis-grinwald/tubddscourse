{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product recommendation engine\n",
    "---\n",
    "![](resources/groceries.jpg)\n",
    "\n",
    "## Main objective:\n",
    "---\n",
    "Imagine we are a grocery store owner, and we are trying to maximize the purchases of our customers per visit. \n",
    "\n",
    "A first strategy that comes to our mind is placing products next to each other that are usually bought together.\n",
    "\n",
    "Since we have succesfully completed a Data Science task in the past we immediately realize that this problem can be formulated as a recommendation task.\n",
    "\n",
    "Essentially we will try to predict the last item of a customers purchase list, given all the other items that he has already in his shopping basket. Those predictions are a helpful first heuristic for the placement of certain products in our grocery store. \n",
    "\n",
    "Thus we start collecting the purchase histories of past customers and start writing down the following steps needed, to build our recommendation pipeline:\n",
    "\n",
    "\n",
    "### Plan of attack:\n",
    "1. Load the customer purchase data, located in 'data/training_data.csv', 'data/training_labels.csv'\n",
    "    - Note on the dataset: Each row in each of the data files refers to one 'incomplete' item-list of a customers purchase.\n",
    "    - The labels represent the item that was purchased by the customer in addition to the items in the dataset\n",
    "    \n",
    "2. Plot the following statistics:\n",
    "    - histogram of 10 most purchased products\n",
    "    - pie chart of all product purchase frequencies\n",
    "\n",
    "\n",
    "3. Compute and present the following results(you are free to choose any method to present your results):\n",
    "    - Find the pair of products, that are bought together the most\n",
    "    - How many customers purchased all the products \n",
    "    - Which product was the least purchased ?\n",
    "    \n",
    "4. Transform it into a Machine learning-classifier digestable format:\n",
    "    - Machine learning algorithms consume data, that has a unified format!\n",
    "    - For example:\n",
    "    \n",
    "    \n",
    "    | feature 1(e.g. product/grocery): | feature 2: | ... | feature N: |\n",
    "    | \"apple\"                          | \"banana\"   | ... | mango      |\n",
    "    --------------------------------------------------------------------\n",
    "    | no                               | yes        | ... | no         | <- customer 1: purchased only banana \n",
    "    --------------------------------------------------------------------\n",
    "    | yes                              | yes        | ... | yes        | <- customer 2: purchased all 3 shown\n",
    "    -------------------------------------------------------------------- \n",
    "                                .\n",
    "                                .\n",
    "                                .\n",
    "    --------------------------------------------------------------------\n",
    "    | no                              | no         | ... | no          | <- customer N: purchased nothing\n",
    "    --------------------------------------------------------------------\n",
    "    \n",
    "\n",
    "5. Train your model on the training set, and predict an item for the each row in the test set(DON'T change the order of the test set):\n",
    "    - Item-predictions should be in the original string format(=item name)\n",
    "\n",
    "\n",
    "6. Save the predictions for the test set in a csv-file\n",
    "\n",
    "\n",
    "### Note on implementation:\n",
    "- You are free to use any classification algorithm that you want. If you find better recommendation approaches on the web(there certainly are better, but also more involved ones), you are free to use those. The main goal though will be to \n",
    "- Try to implement classes\n",
    "\n",
    "### Note on grading:\n",
    "- End result = 25%\n",
    "- Clean code(e.g. classes instead of script like functions etc.) = 25 %\n",
    "- Documentation = 25%\n",
    "- Usage of numpy, pandas, pyplot etc. functions for faster computation = 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pd.read_csv('data/training_data.csv', header=None)\n",
    "test_x = pd.read_csv('data/test_data.csv', header=None)\n",
    "train_y = pd.read_csv('data/training_labels.csv', header=None)\n",
    "test_y = pd.read_csv('data/test_labels.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = train_x.fillna('NaN').to_numpy()\n",
    "test_data = test_x.fillna('NaN').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_products = np.unique(training_data.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' asparagus', 'NaN', 'almonds', 'antioxydant juice', 'asparagus',\n",
       "       'avocado', 'babies food', 'bacon', 'barbecue sauce', 'black tea',\n",
       "       'blueberries', 'body spray', 'bramble', 'brownies', 'bug spray',\n",
       "       'burger sauce', 'burgers', 'butter', 'cake', 'candy bars',\n",
       "       'carrots', 'cauliflower', 'cereals', 'champagne', 'chicken',\n",
       "       'chili', 'chocolate', 'chocolate bread', 'chutney', 'cider',\n",
       "       'clothes accessories', 'cookies', 'cooking oil', 'corn',\n",
       "       'cottage cheese', 'cream', 'dessert wine', 'eggplant', 'eggs',\n",
       "       'energy bar', 'energy drink', 'escalope', 'extra dark chocolate',\n",
       "       'flax seed', 'french fries', 'french wine', 'fresh bread',\n",
       "       'fresh tuna', 'fromage blanc', 'frozen smoothie',\n",
       "       'frozen vegetables', 'gluten free bar', 'grated cheese',\n",
       "       'green beans', 'green grapes', 'green tea', 'ground beef', 'gums',\n",
       "       'ham', 'hand protein bar', 'herb & pepper', 'honey', 'hot dogs',\n",
       "       'ketchup', 'light cream', 'light mayo', 'low fat yogurt',\n",
       "       'magazines', 'mashed potato', 'mayonnaise', 'meatballs', 'melons',\n",
       "       'milk', 'mineral water', 'mint', 'mint green tea', 'muffins',\n",
       "       'mushroom cream sauce', 'napkins', 'nonfat milk', 'oatmeal', 'oil',\n",
       "       'olive oil', 'pancakes', 'parmesan cheese', 'pasta', 'pepper',\n",
       "       'pet food', 'pickles', 'protein bar', 'red wine', 'rice', 'salad',\n",
       "       'salmon', 'salt', 'sandwich', 'shallot', 'shampoo', 'shrimp',\n",
       "       'soda', 'soup', 'spaghetti', 'sparkling water', 'spinach',\n",
       "       'strawberries', 'strong cheese', 'tea', 'tomato juice',\n",
       "       'tomato sauce', 'tomatoes', 'toothpaste', 'turkey',\n",
       "       'vegetables mix', 'water spray', 'white wine', 'whole weat flour',\n",
       "       'whole wheat pasta', 'whole wheat rice', 'yams', 'yogurt cake',\n",
       "       'zucchini'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>salmon</td>\n",
       "      <td>vegetables mix</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>toothpaste</td>\n",
       "      <td>low fat yogurt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>herb &amp; pepper</td>\n",
       "      <td>shrimp</td>\n",
       "      <td>milk</td>\n",
       "      <td>spinach</td>\n",
       "      <td>cake</td>\n",
       "      <td>chili</td>\n",
       "      <td>green tea</td>\n",
       "      <td>light mayo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0               1     2        3     4      5          6   \\\n",
       "0            NaN             NaN   NaN      NaN   NaN    NaN        NaN   \n",
       "1         salmon  vegetables mix   NaN      NaN   NaN    NaN        NaN   \n",
       "2            NaN             NaN   NaN      NaN   NaN    NaN        NaN   \n",
       "3     toothpaste  low fat yogurt   NaN      NaN   NaN    NaN        NaN   \n",
       "4  herb & pepper          shrimp  milk  spinach  cake  chili  green tea   \n",
       "\n",
       "           7    8    9    10   11   12   13   14   15   16   17   18  \n",
       "0         NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "1         NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "2         NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "3         NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "4  light mayo  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_products = np.delete(all_products, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = None\n",
    "for idx, row in enumerate(training_data):\n",
    "    if idx == 0:\n",
    "        X_train = np.array([e in row for e in final_products]).astype(int)\n",
    "    else:\n",
    "        new_row = np.array([e in row for e in final_products]).astype(int)\n",
    "        X_train = np.vstack([X_train, new_row])\n",
    "        \n",
    "X_test = None\n",
    "for idx, row in enumerate(test_data):\n",
    "    if idx == 0:\n",
    "        X_test = np.array([e in row for e in final_products]).astype(int)\n",
    "    else:\n",
    "        new_row = np.array([e in row for e in final_products]).astype(int)\n",
    "        X_test = np.vstack([X_test, new_row])\n",
    "\n",
    "y_train = np.array([np.where(final_products == e) for e in train_y[0]]).reshape(-1)\n",
    "y_test = np.array([np.where(final_products == e) for e in test_y[0]]).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dg/envs/ds/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "trained_model = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = trained_model.predict(X_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24533333333333332"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(train_predictions, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = trained_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1904127829560586"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trained_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1904127829560586"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(predictions, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
