{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch, torchvision\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks using PyTorch framework\n",
    "---\n",
    "![](resources/torch.png)\n",
    "## Comparing performance of classical networks to convolutional neural networks \n",
    "\n",
    "## Typical Deep Learning workflow:\n",
    "\n",
    "1. Load your training datasets, and(if needed) convert them into PyTorch datasets\n",
    "2. Build PyTorch-DataLoaders using your datasets, set shuffle = True and define batch size\n",
    "3. Define the neural network structure\n",
    "4. Training process:\n",
    "    - Define optimizer\n",
    "    - Define loss function\n",
    "    - Define # of training iterations\n",
    "    - Train your model\n",
    "5. Evaluation process:\n",
    "    - Use your model to predict labels for your test set\n",
    "    - evaluate accuracy with true labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Pair programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "training_data = torchvision.datasets.MNIST('data/', train=True, download=True, transform=transform)\n",
    "testing_data = torchvision.datasets.MNIST('data/', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the data more closely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_point = training_data.data[0]\n",
    "test_target = training_data.targets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Shape of data sample: {np.array(test_data_point).shape}')\n",
    "print(f'First row of data sample: {np.array(test_data_point)[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.imshow(test_data_point)\n",
    "plt.show()\n",
    "\n",
    "print(f'Label: {test_target}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataloaders to feed data into our neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_loader = torch.utils.data.DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(testing_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.linear_layer1 = torch.nn.Linear(self.input_dim, 100)\n",
    "        self.linear_layer2 = torch.nn.Linear(100, 50)\n",
    "        self.linear_layer3 = torch.nn.Linear(50, self.num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Layer 1 + activation\n",
    "        x = self.linear_layer1(x.view(-1, self.input_dim))\n",
    "        x = F.sigmoid(x)\n",
    "        \n",
    "        # Layer 2 + activation\n",
    "        x = self.linear_layer2(x)\n",
    "        x = F.sigmoid(x)\n",
    "        \n",
    "        # Layer 3 + activation\n",
    "        x = self.linear_layer3(x)\n",
    "        x = F.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an object of the neural network\n",
    "# Optimizer\n",
    "# Define a Loss Function\n",
    "# Run the training loop\n",
    "\n",
    "neural_net = NeuralNet(784, 10)\n",
    "optimizer = torch.optim.SGD(params=neural_net.parameters(), lr=0.01)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# training loop:\n",
    "\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, (x, y) in enumerate(train_loader, 1):\n",
    "        \n",
    "        # set optimizer gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass\n",
    "        predictions = neural_net.forward(x)\n",
    "        \n",
    "        # backward pass + optimization step\n",
    "        loss = loss_fn(predictions, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            print(f'Epoch: {epoch}, loss: {running_loss / i}')\n",
    "        \n",
    "    print(f'Loss after epoch: {epoch} = {running_loss / len(train_loader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = neural_net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare regular Multilayer-perceptron performance against Convolutional neural network\n",
    "\n",
    "### How to compute output size after convolutional layer ??:\n",
    "- If you just set the channel input size, channel output size, kernel size for your Conv2D function -> output width = input_width - kernel_width + 1\n",
    "- Same for output height\n",
    "\n",
    "### How to compute output size after pooling layer ??:\n",
    "- If you just set the kernel size of your pooling layer, without inputing any other arguments -> output width = input_width / kernel_width\n",
    "- Same for output height\n",
    "\n",
    "#### If you change other input arguments to the Conv/MaxPool functions, the output sizes will be computed as explained in the docs:\n",
    "https://pytorch.org/docs/stable/nn.html#torch.nn.Conv2d\n",
    "\n",
    "- Nice visualizations of different kernel/filter/convolution strategies: https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = torch.nn.Conv2d(6, 16, 5)\n",
    "        self.pool = torch.nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = torch.nn.Linear(120, 84)\n",
    "        self.fc3 = torch.nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Input(batch_size, 1, 28, 28)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        \n",
    "        # Input(batch_size, 6, 24, 24)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # Input(batch_size, 16, 12, 12)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        \n",
    "        # Input(batch_size, 16, 8, 8)\n",
    "        x = self.pool()\n",
    "        \n",
    "        # Input(batch_size, 16, 4, 4)\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an object of the neural network\n",
    "# Optimizer\n",
    "# Define a Loss Function\n",
    "# Run the training loop\n",
    "\n",
    "neural_net = ConvNet()\n",
    "optimizer = torch.optim.SGD(params=neural_net.parameters(), lr=0.01)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop:\n",
    "for epoch in range(10):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, (x, y) in enumerate(train_loader, 1):\n",
    "        \n",
    "        # set optimizer gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass\n",
    "        predictions = neural_net.forward(x)\n",
    "        \n",
    "        # backward pass + optimization step\n",
    "        loss = loss_fn(predictions, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            print(f'Epoch: {epoch}, loss: {running_loss / i}')\n",
    "        \n",
    "    print(f'\\nLoss after epoch: {epoch} = {running_loss / len(train_loader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = neural_net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Build your own Neural Network classifiers:\n",
    "\n",
    "### Todos:\n",
    "1. Load the CIFAR 10 train and test dataset from the torchvision library that we have used above for the MNIST data:\n",
    "Documentation: https://pytorch.org/docs/stable/torchvision/datasets.html\n",
    "\n",
    "2. Create DataLoaders for the training and test size:\n",
    "    - experiment with different batch sizes\n",
    "3. Create one fully connected model and another Convolutional Neural Network, for each experiment with different layer sizes(# of neurons) and layer types:\n",
    "    - Conv layers preprocess the data\n",
    "    - Pooling layers preprocess the data\n",
    "    - Fully connected layer need to be added at the end to classify the data\n",
    "\n",
    "4. Evaluate the prediction accuracy(all correct classified points / number of points) of your Fully-connected and Convolutional Neural Networks\n",
    "\n",
    "5. Evaluate prediction accuracy of each class, e.g.: Correctly classified: 60% of planes, 70% of cars, 30% of housed etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
