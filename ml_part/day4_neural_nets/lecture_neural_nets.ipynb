{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML vs Deep Learning\n",
    "In ML humans design/engineer good features to use for classification. For example picking only features that highlight the direction of highest variance in the data.\n",
    "\n",
    "In Deep Learning we usually input all the (cleaned)data into our neural network which then learns the necessary features for classification itself.\n",
    "![Binary classification](resources/ml_vs_dl.png)\n",
    "\n",
    "# Fully-connected neural networks for classification\n",
    "The main building block of a neural network, is suprise, a neuron. The neuron puts a weight on each of its input features that can be learned and sums up all the weight-input products before passing it through an activation function. Following up inner working of such a neuron.\n",
    "## Main building block - The neuron/hidden unit::\n",
    "![Binary classification](resources/neuron.png)\n",
    "## What are the activation functions f?\n",
    "![Binary classification](resources/activation_functions.png)\n",
    "### Looks just like logistic regression, doesn't it ?\n",
    "\n",
    "\n",
    "## Idea: Stack many of these small classifiers to be capable of representing much more complex decision boundaries:\n",
    "![Binary classification](resources/hidden_layer.png)\n",
    "### Intuitive explanation:\n",
    "Each neuron acts as a sigmoid(linear decision boundary). By assigning weights to each, adding them up and passing them through another nonlinearity(sigmoid function), we are able to create much more complex decision boundaries\n",
    "![Binary classification](resources/bumps.png)\n",
    "\n",
    "## Feedforward neural network:\n",
    "### Properties:\n",
    "#### Input layer:\n",
    "Each node represents a feature from the dataset\n",
    "#### Hidden layer:\n",
    "Each node represents a new learned feature from the original dataset features\n",
    "#### Output layer:\n",
    "Each node represents a label, it's output value represents the prediction probability for the corresponding label. NOTE: They must sum to one\n",
    "## Deep neural network adds many hidden layers:\n",
    "![Binary classification](resources/dnn.jpeg)\n",
    "\n",
    "## Analogy in the human brain\n",
    "Actually the whole idea of deep learning was inspired of the 'architecture' of the human learning machine, the brain. highly connected neurons receive spatio-temproal inputs from neurons and pass them to their neighbors, if some potential threshold is reached. \n",
    "![Binary classification](resources/real_neurons.jpeg)\n",
    "Thus our senses and upcoming layers of neuron likely act as feature extractors that in the end are used to classify the inputs(visual cortex, auditory cortex etc.)\n",
    "![Binary classification](resources/brain.png)\n",
    "\n",
    "## Training a DNN\n",
    "## Backpropagation algorithm:\n",
    "### Main Idea:\n",
    "- computes how to the output error changes with respect to changing each weight in the neural network.\n",
    "\n",
    "### For a better understanding scroll through these couple of pages:\n",
    "https://google-developers.appspot.com/machine-learning/crash-course/backprop-scroll/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "- Usually used for image data, that has high-dimensionality\n",
    "## Essential idea: Apply filters(feature engineering) before classifying the image\n",
    "\n",
    "## Architecture:\n",
    "---\n",
    "![Binary classification](resources/conv_net.jpg)\n",
    "\n",
    "## Filters/Convolutions/Kernels:\n",
    "![Binary classification](resources/filters.ppm)\n",
    "\n",
    "## Example of learned features:\n",
    "![Binary classification](resources/learned_features.png)\n",
    "\n",
    "## Pooling layers:\n",
    "![Binary classification](resources/pooling.jpeg)\n",
    "\n",
    "## Training algorithm: Backprop\n",
    "\n",
    "## Pros:\n",
    "- learns 'sparser' feature representation of image\n",
    "- learn which features are relevant\n",
    "\n",
    "## Cons:\n",
    "- needs quite a lot of training data to train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks\n",
    "Well-suited for time-series data(speech, time-dependent curves etc.)\n",
    "\n",
    "## Architecture:\n",
    "---\n",
    "![Binary classification](resources/rnn.svg)\n",
    "\n",
    "## Example application: Sentiment Analysis\n",
    "---\n",
    "![Binary classification](resources/sentiment.jpeg)\n",
    "\n",
    "## Training algorithm: Backprop\n",
    "\n",
    "## Pros:\n",
    "- capable of learning temporal patterns of the input data\n",
    "- manyvariations(LSTM, bi-directional etc.)\n",
    "\n",
    "## Cons:\n",
    "- takes a long time to train, requires a lot of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 popular open-source neural network frameworks: \n",
    "- Tensorflow(Google): https://www.tensorflow.org/\n",
    "- PyTorch(Facebook): https://pytorch.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
